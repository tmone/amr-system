{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHqP2KjXqCIF",
        "outputId": "2852c6e9-8521-4ba7-911b-2bcb73b9bb55"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Admin/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install ultralytics\n",
        "!pip install kagglehub\n",
        "!pip install pyyaml\n",
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci-t2-curw-x",
        "outputId": "420a8e94-af44-4a9c-f358-42c2b2b9a334"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Import and check pytorch with CUDA\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VxSe-AQlMeu7"
      },
      "outputs": [],
      "source": [
        "# Code to run in new cell after model training\n",
        "\n",
        "from google.colab import files\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def predict_uploaded_image(trainer):\n",
        "    \"\"\"\n",
        "    Upload image and predict using trained model\n",
        "    \"\"\"\n",
        "    print(\"Select image to upload...\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No image uploaded!\")\n",
        "        return\n",
        "\n",
        "    # Create temporary directory to save image\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        for filename, content in uploaded.items():\n",
        "            # Save image to temp directory\n",
        "            temp_path = os.path.join(temp_dir, filename)\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            print(f\"\\nDự đoán cho ảnh: {filename}\")\n",
        "            # Thực hiện dự đoán\n",
        "            trainer.predict_and_visualize(temp_path, conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcGNgk6fJDrZ",
        "outputId": "bf1926ce-8628-405e-8bed-883167def6c4"
      },
      "outputs": [],
      "source": [
        "# Install Segment anything to focus to cell from uploaded image\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b_t1STFyJUGQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import tempfile\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "class BloodCellSegmentPredictor:\n",
        "    def __init__(self, trainer, sam_checkpoint=\"sam_vit_h_4b8939.pth\"):\n",
        "        \"\"\"\n",
        "        Initialize predictor with SAM and YOLO model\n",
        "\n",
        "        Args:\n",
        "            trainer: Trained BloodCellTrainer object\n",
        "            sam_checkpoint: Path to SAM weights\n",
        "        \"\"\"\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # Load SAM model\n",
        "        if not os.path.exists(sam_checkpoint):\n",
        "            print(\"Downloading SAM checkpoint...\")\n",
        "            !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "        # Khởi tạo SAM\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        sam = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint)\n",
        "        sam.to(device=device)\n",
        "\n",
        "        # Khởi tạo mask generator\n",
        "        self.mask_generator = SamAutomaticMaskGenerator(\n",
        "            model=sam,\n",
        "            points_per_side=32,\n",
        "            pred_iou_thresh=0.9,\n",
        "            stability_score_thresh=0.96,\n",
        "            crop_n_layers=1,\n",
        "            crop_n_points_downscale_factor=2,\n",
        "            min_mask_region_area=100,  # Adjust to filter out small regions\n",
        "        )\n",
        "\n",
        "    def extract_cell_regions(self, image):\n",
        "        \"\"\"\n",
        "        Use SAM to segment cell regions\n",
        "\n",
        "        Args:\n",
        "            image: Numpy array BGR image\n",
        "\n",
        "        Returns:\n",
        "            List of (cropped_image, bbox)\n",
        "        \"\"\"\n",
        "        # Convert to RGB for SAM\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Generate masks\n",
        "        masks = self.mask_generator.generate(rgb_image)\n",
        "\n",
        "        # Sort masks by area in descending order\n",
        "        sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
        "\n",
        "        cell_regions = []\n",
        "        for mask in sorted_masks:\n",
        "            # Lấy bbox\n",
        "            bbox = mask['bbox']  # x, y, w, h\n",
        "\n",
        "            # Create crop with padding\n",
        "            pad = 10\n",
        "            x1 = max(0, bbox[0] - pad)\n",
        "            y1 = max(0, bbox[1] - pad)\n",
        "            x2 = min(image.shape[1], bbox[0] + bbox[2] + pad)\n",
        "            y2 = min(image.shape[0], bbox[1] + bbox[3] + pad)\n",
        "\n",
        "            # Crop image\n",
        "            cropped = image[y1:y2, x1:x2]\n",
        "\n",
        "            # Add to result list\n",
        "            cell_regions.append({\n",
        "                'crop': cropped,\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'mask': mask['segmentation']\n",
        "            })\n",
        "\n",
        "        return cell_regions\n",
        "\n",
        "    def visualize_segments(self, image, cell_regions):\n",
        "        \"\"\"\n",
        "        Display segmented regions\n",
        "        \"\"\"\n",
        "        # Copy image for drawing\n",
        "        vis_image = image.copy()\n",
        "\n",
        "        # Draw bboxes and masks\n",
        "        for idx, region in enumerate(cell_regions):\n",
        "            x1, y1, x2, y2 = region['bbox']\n",
        "            mask = region['mask']\n",
        "\n",
        "            # Draw bbox\n",
        "            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Draw mask with alpha blending\n",
        "            colored_mask = np.zeros_like(image)\n",
        "            colored_mask[mask] = [0, 0, 255]  # Red color for mask\n",
        "            vis_image = cv2.addWeighted(vis_image, 0.7, colored_mask, 0.3, 0)\n",
        "\n",
        "            # Add label\n",
        "            cv2.putText(vis_image, f\"Cell {idx+1}\", (x1, y1-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "        return vis_image\n",
        "\n",
        "    def predict_regions(self, cell_regions, conf=0.25):\n",
        "        \"\"\"\n",
        "        Predict cell type for each region\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for region in cell_regions:\n",
        "            crop = region['crop']\n",
        "            results = self.trainer.model.predict(crop, conf=conf)\n",
        "\n",
        "            # Lấy thông tin dự đoán\n",
        "            if len(results[0].boxes) > 0:\n",
        "                for box in results[0].boxes:\n",
        "                    pred = {\n",
        "                        'bbox': region['bbox'],\n",
        "                        'class': self.trainer.model.names[int(box.cls[0])],\n",
        "                        'conf': float(box.conf[0])\n",
        "                    }\n",
        "                    predictions.append(pred)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def process_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Process image: segment -> predict -> display\n",
        "        \"\"\"\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(\"Image cannot be read!\")\n",
        "            return\n",
        "\n",
        "        # Segment cell regions\n",
        "        print(\"Detecting segment cell ...\")\n",
        "        cell_regions = self.extract_cell_regions(image)\n",
        "\n",
        "        if not cell_regions:\n",
        "            print(\"Not found!\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(cell_regions)} cell regions\")\n",
        "\n",
        "        # Display segments\n",
        "        vis_image = self.visualize_segments(image, cell_regions)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.title('Segmented Cells')\n",
        "        plt.show()\n",
        "\n",
        "        # Predict each region\n",
        "        print(\"\\nPredicting cell type...\")\n",
        "        predictions = self.predict_regions(cell_regions)\n",
        "\n",
        "        # Display results\n",
        "        result_image = image.copy()\n",
        "        for pred in predictions:\n",
        "            x1, y1, x2, y2 = pred['bbox']\n",
        "            label = f\"{pred['class']} {pred['conf']:.2f}\"\n",
        "\n",
        "            # Draw bbox and label\n",
        "            cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(result_image, label, (x1, y1-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.title('Detection Results')\n",
        "        plt.show()\n",
        "\n",
        "def predict_uploaded_image_with_sam(trainer):\n",
        "    \"\"\"\n",
        "    Upload và dự đoán ảnh với SAM + YOLO\n",
        "    \"\"\"\n",
        "    print(\"Select image to predict...\")\n",
        "\n",
        "    # Initialize predictor\n",
        "    predictor = BloodCellSegmentPredictor(trainer)\n",
        "\n",
        "    # Upload image\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No image uploaded!\")\n",
        "        return\n",
        "\n",
        "    # Process each uploaded image\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        for filename, content in uploaded.items():\n",
        "            # Save image\n",
        "            temp_path = os.path.join(temp_dir, filename)\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            print(f\"\\nProcessing image: {filename}\")\n",
        "            predictor.process_image(temp_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTEKwmk0T60B",
        "outputId": "916c2b40-ea80-4696-ff5e-1900a8ec99c3"
      },
      "outputs": [],
      "source": [
        "# Fix UTF-8 encoding\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq locales\n",
        "!locale-gen en_US.UTF-8\n",
        "!update-locale LANG=en_US.UTF-8\n",
        "\n",
        "import os\n",
        "os.environ[\"LANG\"] = \"en_US.UTF-8\"\n",
        "os.environ[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
        "\n",
        "# Install required libraries\n",
        "!pip install ultralytics kagglehub matplotlib\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "# Download SAM weights\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnw-0fqvQILH",
        "outputId": "61fc83e1-d11e-41bc-abaa-4fd1d63364f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current locale: UTF-8\n",
            "CUDA available: True\n",
            "SAM weights exist: True\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "print(\"Current locale:\", locale.getpreferredencoding())\n",
        "\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# Check SAM weights\n",
        "import os\n",
        "print(\"SAM weights exist:\", os.path.exists(\"sam_vit_h_4b8939.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "bQe6NzzFrXA_",
        "outputId": "d04eab57-30bc-446b-91fb-8c95aa1ed71a"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display, Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"\n",
        "    Download dataset from Kaggle and return the path\n",
        "    \"\"\"\n",
        "    try:\n",
        "        path = kagglehub.dataset_download(\"quangnguynvnnn/bloodcell-yolo-format\")\n",
        "        print(f\"Dataset downloaded successfully to: {path}\")\n",
        "        return Path(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "class BloodCellTrainer:\n",
        "    def __init__(self, model_name='yolov8n.pt'):\n",
        "        \"\"\"\n",
        "        Initialize trainer for blood cell detection\n",
        "        \"\"\"\n",
        "        self.data_dir = download_dataset()\n",
        "        print(f\"Using dataset from: {self.data_dir}\")\n",
        "        self.model = YOLO(model_name)\n",
        "\n",
        "    def prepare_data_yaml(self, class_names):\n",
        "        \"\"\"\n",
        "        Create data.yaml file for training\n",
        "\n",
        "        Args:\n",
        "            class_names: List of class names\n",
        "        \"\"\"\n",
        "        data_yaml = {\n",
        "            'path': str(self.data_dir.absolute()),\n",
        "            'train': 'train/images',\n",
        "            'val': 'valid/images',\n",
        "            'test': 'test/images',\n",
        "            'names': {i: name for i, name in enumerate(class_names)},\n",
        "            'nc': len(class_names)\n",
        "        }\n",
        "\n",
        "        yaml_path = self.data_dir / 'data.yaml'\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(data_yaml, f)\n",
        "\n",
        "        print(f\"Created data.yaml at: {yaml_path}\")\n",
        "        return str(yaml_path)\n",
        "\n",
        "    def split_dataset(self, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "        \"\"\"\n",
        "        Split dataset into train/val/test\n",
        "        \"\"\"\n",
        "        # Create directories\n",
        "        splits = ['train', 'valid', 'test']\n",
        "        for split in splits:\n",
        "            for subdir in ['images', 'labels']:\n",
        "                split_dir = self.data_dir / split / subdir\n",
        "                split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # List all image files\n",
        "        image_dir = self.data_dir / 'images'\n",
        "        label_dir = self.data_dir / 'labels'\n",
        "\n",
        "        image_files = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
        "        print(f\"Found {len(image_files)} images in dataset\")\n",
        "\n",
        "        # Shuffle and split\n",
        "        random.shuffle(image_files)\n",
        "        n = len(image_files)\n",
        "        train_end = int(n * train_ratio)\n",
        "        val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "        splits_files = {\n",
        "            'train': image_files[:train_end],\n",
        "            'valid': image_files[train_end:val_end],\n",
        "            'test': image_files[val_end:]\n",
        "        }\n",
        "\n",
        "        # Copy files\n",
        "        for split, files in splits_files.items():\n",
        "            print(f\"\\nProcessing {split} split ({len(files)} images)...\")\n",
        "            for img_path in files:\n",
        "                # Copy image\n",
        "                shutil.copy2(img_path,\n",
        "                           self.data_dir / split / 'images' / img_path.name)\n",
        "\n",
        "                # Copy corresponding label file\n",
        "                label_path = label_dir / (img_path.stem + '.txt')\n",
        "                if label_path.exists():\n",
        "                    shutil.copy2(label_path,\n",
        "                               self.data_dir / split / 'labels' / label_path.name)\n",
        "\n",
        "    def train(self, epochs=100, batch_size=16, img_size=640):\n",
        "        \"\"\"\n",
        "        Training model\n",
        "        \"\"\"\n",
        "        # Load data.yaml path\n",
        "        yaml_path = str(self.data_dir / 'data.yaml')\n",
        "\n",
        "        # Training configuration\n",
        "        self.model.train(\n",
        "            data=yaml_path,\n",
        "            epochs=epochs,\n",
        "            batch=batch_size,\n",
        "            imgsz=img_size,\n",
        "            device='0' if torch.cuda.is_available() else 'cpu',\n",
        "            patience=50,\n",
        "            save=True,\n",
        "            project='blood_cell_detection',\n",
        "            name='train',\n",
        "            exist_ok=True,\n",
        "            pretrained=True,\n",
        "            optimizer='Adam',\n",
        "            lr0=0.001,\n",
        "            weight_decay=0.0005,\n",
        "            warmup_epochs=3,\n",
        "            close_mosaic=10,\n",
        "            augment=True,\n",
        "            cache=False,\n",
        "            workers=8,\n",
        "            save_period=10,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Validate model and display readable metrics\n",
        "        \"\"\"\n",
        "        yaml_path = str(self.data_dir / 'data.yaml')\n",
        "        results = self.model.val(data=yaml_path, split='val')\n",
        "\n",
        "        # Format metrics into readable format\n",
        "        metrics = {\n",
        "            'mAP50': float(results.box.map50),\n",
        "            'mAP50-95': float(results.box.map),\n",
        "            'precision': float(results.box.mp),\n",
        "            'recall': float(results.box.mr)\n",
        "        }\n",
        "\n",
        "        # Display metrics in table format\n",
        "        print(\"\\n=== Model Performance Metrics ===\")\n",
        "        print(f\"{'Metric':<15} {'Value':>10}\")\n",
        "        print(\"-\" * 30)\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric:<15} {value:>10.4f}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def predict_and_visualize(self, image_path, conf=0.25):\n",
        "        \"\"\"\n",
        "        Predict and display results on image\n",
        "        \"\"\"\n",
        "        # Perform prediction\n",
        "        results = self.model.predict(image_path, conf=conf)\n",
        "\n",
        "        # Get image with drawn boxes\n",
        "        plotted_img = results[0].plot()\n",
        "\n",
        "        # Chuyển từ BGR sang RGB\n",
        "        plotted_img_rgb = cv2.cvtColor(plotted_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Hiển thị ảnh sử dụng matplotlib\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(plotted_img_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.title('Detection Results')\n",
        "        plt.show()\n",
        "\n",
        "        # In kết quả dự đoán\n",
        "        print(\"\\n=== Detection Results ===\")\n",
        "        boxes = results[0].boxes\n",
        "        for box in boxes:\n",
        "            # Get box coordinates\n",
        "            x1, y1, x2, y2 = box.xyxy[0]\n",
        "            # Get class and confidence\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            # Get class name from model\n",
        "            class_name = self.model.names[cls]\n",
        "            print(f\"Class: {class_name:<10} Confidence: {conf:.4f}\")\n",
        "\n",
        "    def predict_folder(self, folder_path, num_images=5, conf=0.25):\n",
        "        \"\"\"\n",
        "        Predict multiple images from a folder\n",
        "        \"\"\"\n",
        "        # Get list of images\n",
        "        image_files = list(Path(folder_path).glob('*.jpg')) + list(Path(folder_path).glob('*.png'))\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"No images found in {folder_path}\")\n",
        "            return\n",
        "\n",
        "        # Randomly select number of images to predict\n",
        "        selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
        "\n",
        "        # Predict and display each image\n",
        "        for img_path in selected_images:\n",
        "            print(f\"\\nProcessing image: {img_path.name}\")\n",
        "            self.predict_and_visualize(str(img_path), conf=conf)\n",
        "\n",
        "global_trainer = None\n",
        "\n",
        "def initialize_global_trainer(model_path=None):\n",
        "    \"\"\"Initialize global trainer with optional pre-trained model\"\"\"\n",
        "    global global_trainer\n",
        "    trainer = BloodCellTrainer(model_name='yolov8n.pt')\n",
        "    \n",
        "    # Prepare data.yaml\n",
        "    class_names = ['rbc', 'wbc', 'platelets']\n",
        "    trainer.prepare_data_yaml(class_names)\n",
        "    \n",
        "    # Split dataset\n",
        "    trainer.split_dataset()\n",
        "    \n",
        "    # Load pre-trained weights if provided\n",
        "    if model_path and os.path.exists(model_path):\n",
        "        print(f\"Loading pre-trained model from {model_path}\")\n",
        "        trainer.model = YOLO(model_path)\n",
        "    \n",
        "    global_trainer = trainer\n",
        "    return trainer\n",
        "\n",
        "def main(train_model=False):\n",
        "    \"\"\"\n",
        "    Initialize and optionally train the model\n",
        "    Args:\n",
        "        train_model: Boolean to indicate if training should be performed\n",
        "    \"\"\"\n",
        "    global global_trainer\n",
        "    \n",
        "    # Use existing trainer or create new one\n",
        "    trainer = global_trainer if global_trainer is not None else initialize_global_trainer()\n",
        "    \n",
        "    if train_model:\n",
        "        print(\"Starting model training...\")\n",
        "        trainer.train(epochs=10)\n",
        "        print(\"\\nValidating model...\")\n",
        "        metrics = trainer.validate()\n",
        "        \n",
        "        # Save trained model\n",
        "        save_path = 'blood_cell_detection/train/weights/best.pt'\n",
        "        if os.path.exists(save_path):\n",
        "            print(f\"\\nSaved trained model to {save_path}\")\n",
        "            # Update global trainer with trained model\n",
        "            initialize_global_trainer(save_path)\n",
        "    \n",
        "    return global_trainer\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction cell - can be run multiple times\n",
        "print(\"=== Blood Cell Detection with Segment Anything ===\")\n",
        "print(\"Note: This cell can be run multiple times to process different images\")\n",
        "\n",
        "try:\n",
        "    predict_uploaded_image_with_sam(global_trainer)\n",
        "except NameError:\n",
        "    print(\"Error: Trainer not initialized. Please run the initialization cell first.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")\n",
        "    print(\"Please ensure the model is properly initialized before running predictions\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
