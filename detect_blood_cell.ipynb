{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmone/amr-system/blob/main/detect_blood_cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FShaoqp489op",
        "outputId": "01dddfab-4d04-42fa-917d-f2de28ed4ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.71)\n",
            "Requirement already satisfied: metrics in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: Pygments==2.2.0 in /usr/local/lib/python3.10/dist-packages (from metrics) (2.2.0)\n",
            "Requirement already satisfied: pathspec==0.5.5 in /usr/local/lib/python3.10/dist-packages (from metrics) (0.5.5)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from metrics) (2.3.7.post1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# prompt: Cài đặt các thư viện cần thiết để training hình ảnh tể bào máu\n",
        "\n",
        "!pip install tensorflow opencv-python matplotlib ultralytics metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkKorQSZ9O3U",
        "outputId": "77331ec0-1fc6-4a12-c27d-ee502c0449ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/quangnguynvnnn/bloodcell-yolo-format?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 308M/308M [00:07<00:00, 41.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/quangnguynvnnn/bloodcell-yolo-format/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"quangnguynvnnn/bloodcell-yolo-format\")\n",
        "\n",
        "print(\"Path to dataset files:\", dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j1LfXgEDI8oO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "    # Convert to coordinates format\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    xi1 = max(x1 - w1/2, x2 - w2/2)\n",
        "    yi1 = max(y1 - h1/2, y2 - h2/2)\n",
        "    xi2 = min(x1 + w1/2, x2 + w2/2)\n",
        "    yi2 = min(y1 + h1/2, y2 + h2/2)\n",
        "\n",
        "    # Calculate areas\n",
        "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "def calculate_ap(recalls, precisions):\n",
        "    \"\"\"Calculate Average Precision using the 11-point interpolation\"\"\"\n",
        "    ap = 0\n",
        "    for t in np.arange(0, 1.1, 0.1):\n",
        "        if np.sum(recalls >= t) == 0:\n",
        "            p = 0\n",
        "        else:\n",
        "            p = np.max(precisions[recalls >= t])\n",
        "        ap += p / 11\n",
        "    return ap\n",
        "\n",
        "def calculate_metrics(results, iou_threshold=0.5, conf_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate detection metrics including mAP, precision, recall\n",
        "\n",
        "    Args:\n",
        "        results: List of detection results, each containing predictions and ground truth\n",
        "        iou_threshold: IoU threshold for considering a detection as correct\n",
        "        conf_threshold: Confidence threshold for filtering detections\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing calculated metrics\n",
        "    \"\"\"\n",
        "    metrics = defaultdict(list)\n",
        "\n",
        "    for result in results:\n",
        "        # Extract predictions and ground truth\n",
        "        preds = result.boxes.data.cpu().numpy()  # Assuming YOLO format results\n",
        "        if hasattr(result, 'ground_truth'):\n",
        "            gt = result.ground_truth.cpu().numpy()\n",
        "        else:\n",
        "            continue  # Skip if no ground truth available\n",
        "\n",
        "        # Filter predictions by confidence\n",
        "        preds = preds[preds[:, 4] >= conf_threshold]\n",
        "\n",
        "        # Calculate metrics per class\n",
        "        classes = np.unique(np.concatenate([preds[:, 5], gt[:, 0]]))\n",
        "\n",
        "        for cls in classes:\n",
        "            cls_preds = preds[preds[:, 5] == cls]\n",
        "            cls_gt = gt[gt[:, 0] == cls]\n",
        "\n",
        "            # Sort predictions by confidence\n",
        "            cls_preds = cls_preds[(-cls_preds[:, 4]).argsort()]\n",
        "\n",
        "            # Initialize arrays for tracking matches\n",
        "            detected_gt = np.zeros(len(cls_gt))\n",
        "\n",
        "            true_positives = np.zeros(len(cls_preds))\n",
        "            false_positives = np.zeros(len(cls_preds))\n",
        "\n",
        "            # Match predictions to ground truth\n",
        "            for pred_idx, pred in enumerate(cls_preds):\n",
        "                best_iou = 0\n",
        "                best_gt_idx = -1\n",
        "\n",
        "                for gt_idx, gt_box in enumerate(cls_gt):\n",
        "                    if detected_gt[gt_idx]:\n",
        "                        continue\n",
        "\n",
        "                    iou = calculate_iou(pred[:4], gt_box[1:])\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_gt_idx = gt_idx\n",
        "\n",
        "                if best_iou >= iou_threshold:\n",
        "                    true_positives[pred_idx] = 1\n",
        "                    detected_gt[best_gt_idx] = 1\n",
        "                else:\n",
        "                    false_positives[pred_idx] = 1\n",
        "\n",
        "            # Calculate cumulative values\n",
        "            cum_tp = np.cumsum(true_positives)\n",
        "            cum_fp = np.cumsum(false_positives)\n",
        "\n",
        "            # Calculate precision and recall\n",
        "            recalls = cum_tp / len(cls_gt) if len(cls_gt) > 0 else np.zeros_like(cum_tp)\n",
        "            precisions = cum_tp / (cum_tp + cum_fp)\n",
        "\n",
        "            # Calculate AP for this class\n",
        "            ap = calculate_ap(recalls, precisions)\n",
        "\n",
        "            # Store metrics\n",
        "            metrics['ap_per_class'].append(ap)\n",
        "            metrics['precision_per_class'].append(np.mean(precisions))\n",
        "            metrics['recall_per_class'].append(np.mean(recalls))\n",
        "\n",
        "    # Calculate mean metrics\n",
        "    metrics['mAP'] = np.mean(metrics['ap_per_class'])\n",
        "    metrics['mean_precision'] = np.mean(metrics['precision_per_class'])\n",
        "    metrics['mean_recall'] = np.mean(metrics['recall_per_class'])\n",
        "\n",
        "    return dict(metrics)  # Convert defaultdict to regular dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBm3nYDPJQpy",
        "outputId": "38b00332-fe8f-46d6-a769-4b6c70db12c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-3fc80ee12f56>:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=torch.cuda.is_available())  # Enable automatic mixed precision\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.cuda.amp as amp\n",
        "import gc\n",
        "from contextlib import contextmanager\n",
        "import sys\n",
        "\n",
        "@contextmanager\n",
        "def manage_memory():\n",
        "    \"\"\"Context manager for managing memory in Colab\"\"\"\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        # Clear memory\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        # If in Colab, use shell commands for additional cleanup\n",
        "        if 'google.colab' in sys.modules:\n",
        "            try:\n",
        "                import IPython\n",
        "                IPython.get_ipython().system('nvidia-smi')\n",
        "                IPython.get_ipython().system('kill -9 $(nvidia-smi | grep \"python\" | awk \'{print $5}\')')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "def reset_cuda_memory():\n",
        "    \"\"\"Force reset CUDA memory\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_max_memory_allocated()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "    gc.collect()\n",
        "\n",
        "class CustomDetector(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Check CUDA availability\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use efficient backbone\n",
        "        backbone = models.efficientnet_b0(pretrained=True)\n",
        "        self.features = nn.Sequential(*list(backbone.children())[:-2])\n",
        "\n",
        "        # Detection head\n",
        "        self.det_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1280, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes * 5)\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.det_head.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Handle both string paths and tensor inputs\n",
        "        if isinstance(x, str):\n",
        "            # Load and preprocess image if path is provided\n",
        "            image = Image.open(x).convert('RGB')\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((640, 640)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            x = transform(image).unsqueeze(0).to(self.device)\n",
        "        \n",
        "        # Ensure input is a tensor\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            raise TypeError(\"Input must be either a tensor or a path string\")\n",
        "\n",
        "        # Extract features\n",
        "        features = self.features(x)\n",
        "        \n",
        "        # Generate detections\n",
        "        detections = self.det_head(features)\n",
        "        \n",
        "        # Reshape output to [batch_size, num_predictions, 5]\n",
        "        return detections.view(x.shape[0], -1, 5)\n",
        "\n",
        "class DetectionLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.reg_loss = nn.SmoothL1Loss(reduction='mean')\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            predictions: [batch_size, num_predictions, 5]\n",
        "            targets: [batch_size, max_targets, 5]\n",
        "        \"\"\"\n",
        "        batch_size = predictions.shape[0]\n",
        "        num_predictions = predictions.shape[1]\n",
        "\n",
        "        # Split predictions into classification and regression\n",
        "        pred_cls = predictions[..., 0]  # [batch_size, num_predictions]\n",
        "        pred_box = predictions[..., 1:]  # [batch_size, num_predictions, 4]\n",
        "\n",
        "        # Initialize targets with same size as predictions\n",
        "        target_cls = torch.zeros_like(pred_cls)\n",
        "        target_box = torch.zeros_like(pred_box)\n",
        "\n",
        "        # For each item in batch, fill in actual targets\n",
        "        for i in range(batch_size):\n",
        "            # Get valid targets (non-zero rows)\n",
        "            valid_mask = targets[i].sum(dim=1) > 0\n",
        "            valid_targets = targets[i][valid_mask]\n",
        "\n",
        "            if len(valid_targets) > 0:\n",
        "                # Limit number of targets to num_predictions\n",
        "                num_valid = min(len(valid_targets), num_predictions)\n",
        "                target_cls[i, :num_valid] = valid_targets[:num_valid, 0]\n",
        "                target_box[i, :num_valid] = valid_targets[:num_valid, 1:]\n",
        "\n",
        "        # Calculate losses\n",
        "        cls_loss = self.bce_loss(pred_cls, target_cls)\n",
        "        box_loss = self.reg_loss(pred_box, target_box)\n",
        "\n",
        "        return cls_loss + box_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx5KRh23GnxN",
        "outputId": "43194f5b-bdf6-4b1e-ab89-4aafe401eeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 57.7MB/s]\n",
            "<ipython-input-5-93d5190e9334>:170: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler() if torch.cuda.is_available() else None\n",
            "Epoch 1/100:   0%|          | 0/375 [00:00<?, ?it/s]<ipython-input-5-93d5190e9334>:192: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "Epoch 1/100: 100%|██████████| 375/375 [02:55<00:00,  2.14it/s, loss=nan]\n",
            "Validation:   0%|          | 0/63 [00:00<?, ?it/s]<ipython-input-5-93d5190e9334>:308: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "Validation: 100%|██████████| 63/63 [00:27<00:00,  2.29it/s]\n",
            "Epoch 2/100: 100%|██████████| 375/375 [02:48<00:00,  2.22it/s, loss=nan]\n",
            "Validation: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n",
            "Epoch 3/100: 100%|██████████| 375/375 [02:51<00:00,  2.18it/s, loss=nan]\n",
            "Validation: 100%|██████████| 63/63 [00:25<00:00,  2.48it/s]\n",
            "Epoch 4/100:  17%|█▋        | 65/375 [00:31<02:17,  2.26it/s, loss=nan]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.cuda.amp as amp\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import logging\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,expandable_segments:True'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "class BloodCellDataset(Dataset):\n",
        "    def __init__(self, data_path, split='train', transform=None):\n",
        "        # Map 'val' to 'valid' for correct path\n",
        "        split = 'valid' if split == 'val' else split\n",
        "        self.data_path = Path(data_path) / split\n",
        "        self.image_dir = self.data_path / 'images'\n",
        "        self.label_dir = self.data_path / 'labels'\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((640, 640)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.image_files = list(self.image_dir.glob('*.jpg'))\n",
        "        if len(self.image_files) == 0:\n",
        "            raise ValueError(f\"No images found in {self.image_dir}\")\n",
        "\n",
        "        # Verify directory structure\n",
        "        if not self.image_dir.exists():\n",
        "            raise ValueError(f\"Image directory not found: {self.image_dir}\")\n",
        "        if not self.label_dir.exists():\n",
        "            raise ValueError(f\"Label directory not found: {self.label_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Add memory efficient loading\n",
        "        try:\n",
        "            img_path = self.image_files[idx]\n",
        "            label_path = self.label_dir / (img_path.stem + '.txt')\n",
        "\n",
        "            # Use PIL's memory-efficient loading\n",
        "            with Image.open(img_path) as img:\n",
        "                image = img.convert('RGB')\n",
        "                image = self.transform(image)\n",
        "\n",
        "            # Load labels efficiently\n",
        "            targets = []\n",
        "            if label_path.exists():\n",
        "                with open(label_path) as f:\n",
        "                    for line in f:\n",
        "                        class_id, x, y, w, h = map(float, line.strip().split())\n",
        "                        targets.append([class_id, x, y, w, h])\n",
        "\n",
        "            targets = torch.tensor(targets if targets else [[0, 0, 0, 0, 0]], dtype=torch.float32)\n",
        "            return image, targets\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "class BloodCellDetector:\n",
        "    def __init__(self, data_path):\n",
        "        # Setup logging first\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Initialize other attributes\n",
        "        self.data_path = data_path\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "\n",
        "        # Enhanced CUDA checking\n",
        "        if not torch.cuda.is_available():\n",
        "            self.logger.error(\"CUDA is not available! Checking system configuration...\")\n",
        "            self.logger.info(f\"PyTorch version: {torch.__version__}\")\n",
        "            self.logger.info(f\"CUDA version: {torch.version.cuda}\")\n",
        "            self.logger.warning(\"Please run check_gpu.py for detailed diagnostics\")\n",
        "            self.logger.info(\"You may need to reinstall PyTorch with CUDA support:\")\n",
        "            self.logger.info(\"pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Log device info\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            cuda_version = torch.version.cuda\n",
        "\n",
        "            self.logger.info(\"=== GPU Configuration ===\")\n",
        "            self.logger.info(f\"GPU Device: {gpu_name}\")\n",
        "            self.logger.info(f\"CUDA Version: {cuda_version}\")\n",
        "            self.logger.info(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "            self.logger.info(f\"PyTorch CUDA: {torch.version.cuda}\")\n",
        "            self.logger.info(\"=====================\")\n",
        "\n",
        "        # Test CUDA memory allocation\n",
        "        if torch.cuda.is_available():\n",
        "            try:\n",
        "                test_tensor = torch.zeros(1).cuda()\n",
        "                self.logger.info(\"Successfully allocated CUDA memory\")\n",
        "            except RuntimeError as e:\n",
        "                self.logger.error(f\"Failed to allocate CUDA memory: {str(e)}\")\n",
        "\n",
        "        # Verify dataset structure\n",
        "        self.verify_dataset_structure(data_path)\n",
        "\n",
        "    def verify_dataset_structure(self, data_path):\n",
        "        \"\"\"Verify the dataset structure and available splits\"\"\"\n",
        "        path = Path(data_path)\n",
        "        required_splits = ['train', 'valid', 'test']\n",
        "\n",
        "        for split in required_splits:\n",
        "            split_path = path / split\n",
        "            img_path = split_path / 'images'\n",
        "            label_path = split_path / 'labels'\n",
        "\n",
        "            if not split_path.exists():\n",
        "                self.logger.error(f\"Missing {split} directory at {split_path}\")\n",
        "            elif not img_path.exists():\n",
        "                self.logger.error(f\"Missing images directory at {img_path}\")\n",
        "            elif not label_path.exists():\n",
        "                self.logger.error(f\"Missing labels directory at {label_path}\")\n",
        "            else:\n",
        "                img_count = len(list(img_path.glob('*.jpg')))\n",
        "                self.logger.info(f\"Found {img_count} images in {split} split\")\n",
        "\n",
        "    def setup_data_config(self):\n",
        "        data_yaml = {\n",
        "            'path': self.data_path,\n",
        "            'train': 'train/images',\n",
        "            'val': 'valid/images',  # Changed from 'val' to 'valid'\n",
        "            'test': 'test/images',\n",
        "            'names': ['RBC', 'WBC', 'Platelets']\n",
        "        }\n",
        "\n",
        "        with open('data.yaml', 'w') as f:\n",
        "            yaml.dump(data_yaml, f)\n",
        "\n",
        "    def train_yolov8(self, epochs=100):\n",
        "        model = YOLO('yolov8n.pt')\n",
        "        results = model.train(\n",
        "            data='data.yaml',\n",
        "            epochs=epochs,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name='yolov8_blood_cells'\n",
        "        )\n",
        "        self.models['yolov8'] = model\n",
        "        return results\n",
        "\n",
        "    def train_custom_model(self, epochs=100, batch_size=8):\n",
        "        try:\n",
        "            with manage_memory():\n",
        "                # Move model to CPU first to clear GPU memory\n",
        "                if hasattr(self, 'model'):\n",
        "                    self.model.cpu()\n",
        "                    del self.model\n",
        "                    reset_cuda_memory()\n",
        "                \n",
        "                # Initialize new model\n",
        "                model = CustomDetector(num_classes=3)\n",
        "                \n",
        "                # Memory-efficient data loading\n",
        "                train_loader = self.get_data_loader('train', batch_size)\n",
        "                val_loader = self.get_data_loader('val', batch_size)\n",
        "\n",
        "                self.logger.info(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
        "                self.logger.info(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
        "\n",
        "                if len(train_loader) == 0 or len(val_loader) == 0:\n",
        "                    raise ValueError(\"Empty data loader detected\")\n",
        "\n",
        "                model = CustomDetector(num_classes=3).to(self.device)\n",
        "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "                criterion = DetectionLoss()\n",
        "\n",
        "                # Only use GradScaler if CUDA is available\n",
        "                scaler = amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "                # Add gradient accumulation\n",
        "                gradient_accumulation_steps = 4\n",
        "                effective_batch_size = batch_size * gradient_accumulation_steps\n",
        "\n",
        "                best_val_loss = float('inf')\n",
        "                start_time = time.time()\n",
        "\n",
        "                self.logger.info(f\"Starting training on {self.device}\")\n",
        "                self.logger.info(f\"Total batches per epoch: {len(train_loader)}\")\n",
        "\n",
        "                for epoch in range(epochs):\n",
        "                    try:\n",
        "                        epoch_start = time.time()\n",
        "                        model.train()\n",
        "                        total_loss = 0\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        # Use tqdm for progress bar\n",
        "                        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "                        for batch_idx, batch in enumerate(pbar):\n",
        "                            try:\n",
        "                                # Handle None returns from dataset\n",
        "                                if batch is None:\n",
        "                                    continue\n",
        "\n",
        "                                images, targets = batch\n",
        "                                images = images.to(self.device, non_blocking=True)\n",
        "                                targets = targets.to(self.device, non_blocking=True)\n",
        "\n",
        "                                # Clear cache if memory is tight\n",
        "                                if batch_idx % 10 == 0:\n",
        "                                    torch.cuda.empty_cache()\n",
        "\n",
        "                                # Mixed precision training only with CUDA\n",
        "                                if torch.cuda.is_available():\n",
        "                                    with amp.autocast():\n",
        "                                        predictions = model(images)\n",
        "                                        loss = criterion(predictions, targets)\n",
        "                                        loss = loss / gradient_accumulation_steps\n",
        "\n",
        "                                    scaler.scale(loss).backward()\n",
        "\n",
        "                                    if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "                                        scaler.step(optimizer)\n",
        "                                        scaler.update()\n",
        "                                        optimizer.zero_grad()\n",
        "                                else:\n",
        "                                    predictions = model(images)\n",
        "                                    loss = criterion(predictions, targets)\n",
        "                                    loss = loss / gradient_accumulation_steps\n",
        "\n",
        "                                    loss.backward()\n",
        "\n",
        "                                    if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "                                        optimizer.step()\n",
        "                                        optimizer.zero_grad()\n",
        "\n",
        "                                total_loss += loss.item()\n",
        "                                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "                                # Free up memory\n",
        "                                del images, targets, predictions\n",
        "                                torch.cuda.empty_cache()\n",
        "\n",
        "                                # Log GPU memory usage periodically\n",
        "                                if batch_idx % 50 == 0:\n",
        "                                    gpu_memory = torch.cuda.memory_allocated() / 1e9\n",
        "                                    self.logger.debug(f\"GPU Memory used: {gpu_memory:.2f} GB\")\n",
        "                            except RuntimeError as e:\n",
        "                                if \"out of memory\" in str(e):\n",
        "                                    reset_cuda_memory()\n",
        "                                    continue\n",
        "                                raise e\n",
        "\n",
        "                        # Validation with memory optimization\n",
        "                        val_loss = self.validate_model(model, val_loader, criterion)\n",
        "\n",
        "                        # Clean up after each epoch\n",
        "                        reset_cuda_memory()\n",
        "\n",
        "                        epoch_time = time.time() - epoch_start\n",
        "\n",
        "                        # Log epoch statistics\n",
        "                        self.logger.info(\n",
        "                            f\"Epoch {epoch+1}/{epochs} - \"\n",
        "                            f\"Train Loss: {total_loss/len(train_loader):.4f} - \"\n",
        "                            f\"Val Loss: {val_loss:.4f} - \"\n",
        "                            f\"Time: {epoch_time:.2f}s\"\n",
        "                        )\n",
        "\n",
        "                        # Save best model\n",
        "                        if val_loss < best_val_loss:\n",
        "                            best_val_loss = val_loss\n",
        "                            torch.save(model.state_dict(), 'best_model.pt')\n",
        "                            self.logger.info(f\"Saved best model with val_loss: {val_loss:.4f}\")\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error in epoch {epoch}: {str(e)}\")\n",
        "                        reset_cuda_memory()\n",
        "                        continue\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Training error: {str(e)}\")\n",
        "            reset_cuda_memory()\n",
        "            raise\n",
        "        finally:\n",
        "            reset_cuda_memory()\n",
        "\n",
        "    def get_data_loader(self, split, batch_size):\n",
        "        try:\n",
        "            # Map 'val' to 'valid' for consistency\n",
        "            actual_split = 'valid' if split == 'val' else split\n",
        "            self.logger.info(f\"Loading {actual_split} dataset from {self.data_path}\")\n",
        "\n",
        "            dataset = BloodCellDataset(self.data_path, split=actual_split)\n",
        "            if len(dataset) == 0:\n",
        "                raise ValueError(f\"Empty dataset for split: {actual_split}\")\n",
        "\n",
        "            self.logger.info(f\"Successfully loaded {len(dataset)} samples\")\n",
        "\n",
        "            return DataLoader(\n",
        "                dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=(split == 'train'),\n",
        "                num_workers=2,  # Reduced workers\n",
        "                pin_memory=True,\n",
        "                collate_fn=self.collate_fn,\n",
        "                drop_last=True,  # Drop incomplete batches\n",
        "                prefetch_factor=2\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading {actual_split} dataset: {str(e)}\")\n",
        "            self.logger.error(f\"Data path: {self.data_path}\")\n",
        "            self.logger.error(f\"Available directories: {[x.name for x in Path(self.data_path).iterdir()]}\")\n",
        "            raise\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"Collate function for DataLoader\"\"\"\n",
        "        try:\n",
        "            # Filter out None values that might come from failed loading\n",
        "            batch = [b for b in batch if b is not None]\n",
        "            if not batch:\n",
        "                return None\n",
        "            \n",
        "            images, targets = zip(*batch)\n",
        "            images = torch.stack(images)\n",
        "            \n",
        "            # Handle target padding\n",
        "            max_targets = max(t.shape[0] for t in targets)\n",
        "            padded_targets = []\n",
        "            \n",
        "            for t in targets:\n",
        "                pad_size = max_targets - t.shape[0]\n",
        "                if pad_size > 0:\n",
        "                    padding = torch.zeros((pad_size, t.shape[1]), dtype=t.dtype)\n",
        "                    padded_target = torch.cat([t, padding], dim=0)\n",
        "                else:\n",
        "                    padded_target = t\n",
        "                padded_targets.append(padded_target)\n",
        "            \n",
        "            targets = torch.stack(padded_targets)\n",
        "            return images, targets\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in collate_fn: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def validate_model(self, model, val_loader, criterion):\n",
        "        with manage_memory():\n",
        "            try:\n",
        "                if val_loader is None or len(val_loader) == 0:\n",
        "                    self.logger.error(\"Validation loader is empty!\")\n",
        "                    return float('inf')\n",
        "\n",
        "                model.eval()\n",
        "                total_loss = 0\n",
        "                num_batches = 0\n",
        "\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        for images, targets in tqdm(val_loader, desc='Validation'):\n",
        "                            images = images.to(self.device, non_blocking=True)\n",
        "                            targets = targets.to(self.device, non_blocking=True)\n",
        "\n",
        "                            with amp.autocast():\n",
        "                                predictions = model(images)\n",
        "                                loss = criterion(predictions, targets)\n",
        "\n",
        "                            total_loss += loss.item()\n",
        "                            num_batches += 1\n",
        "\n",
        "                    if num_batches == 0:\n",
        "                        self.logger.error(\"No batches processed during validation!\")\n",
        "                        return float('inf')\n",
        "\n",
        "                    return total_loss / num_batches\n",
        "\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error during validation: {str(e)}\")\n",
        "                    reset_cuda_memory()\n",
        "                    return float('inf')\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error during validation: {str(e)}\")\n",
        "                reset_cuda_memory()\n",
        "                return float('inf')\n",
        "\n",
        "    # Train both models\n",
        "    detector.train_custom_model(epochs=100)\n",
        "    detector.train_yolov8(epochs=100)\n",
        "\n",
        "    # Compare results\n",
        "    comparison = detector.compare_models()\n",
        "    print(\"Model Comparison Results:\")\n",
        "            results.append(prediction)\n",
        "\n",
        "        metrics = calculate_metrics(results)\n",
        "        self.results[model_name] = metrics\n",
        "        return metrics\n",
        "\n",
        "    def compare_models(self):\n",
        "        # Update comparison to include both custom and YOLO models\n",
        "        custom_metrics = self.evaluate_model('custom', self.data_path + '/test/images')\n",
        "        yolo_metrics = self.evaluate_model('yolov8', self.data_path + '/test/images')\n",
        "\n",
        "        return {\n",
        "            'custom_model': custom_metrics,\n",
        "            'yolov8': yolo_metrics\n",
        "        }\n",
        "\n",
        "    def visualize_results(self, image_path, model_name):\n",
        "        model = self.models[model_name]\n",
        "        results = model(image_path)\n",
        "\n",
        "        # Plot results\n",
        "        results.plot()\n",
        "        cv2.imshow(f'Detection Results - {model_name}', results.plot())\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        with manage_memory():\n",
        "            if (dataset_path is None):\n",
        "                print(\"Failed to download dataset. Exiting...\")\n",
        "                return\n",
        "\n",
        "            # Initialize detector with downloaded dataset path\n",
        "            detector = BloodCellDetector(data_path=dataset_path)\n",
        "            detector.setup_data_config()\n",
        "\n",
        "            # Train both models\n",
        "            detector.train_custom_model(epochs=100)\n",
        "            detector.train_yolov8(epochs=100)\n",
        "\n",
        "            # Compare results\n",
        "            comparison = detector.compare_models()\n",
        "            print(\"Model Comparison Results:\")\n",
        "            print(comparison)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main: {str(e)}\")\n",
        "        reset_cuda_memory()\n",
        "    finally:\n",
        "        # Final cleanup\n",
        "        reset_cuda_memory()\n",
        "        if 'google.colab' in sys.modules:\n",
        "            import IPython\n",
        "            IPython.get_ipython().system('nvidia-smi')\n",
        "            IPython.get_ipython().system('kill -9 $(nvidia-smi | grep \"python\" | awk \'{print $5}\')')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMbskF388h5ec2kx540p4MZ",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
