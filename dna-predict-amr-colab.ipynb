{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA-based Antimicrobial Resistance Prediction - Colab Version\n",
    "\n",
    "This notebook provides a direct interface for AMR prediction in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow biopython scikit-learn pandas numpy requests\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/tmone/amr-system.git\n",
    "%cd amr-system\n",
    "\n",
    "import sys\n",
    "sys.path.append('./python-app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import tensorflow as tf\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import io\n",
    "import requests\n",
    "import tarfile\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"All required packages imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AMRModel\n",
    "import requests\n",
    "import tarfile\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class DataDownloader:\n",
    "    def __init__(self, base_url=\"https://card.mcmaster.ca/download/0/\", \n",
    "                 filename=\"broadstreet-v3.2.4.tar.bz2\",\n",
    "                 output_dir=\"data\"):\n",
    "        self.base_url = base_url\n",
    "        self.filename = filename\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def download_file(self):\n",
    "        \"\"\"Download data file with progress bar\"\"\"\n",
    "        url = f\"{self.base_url}{self.filename}\"\n",
    "        target_path = self.output_dir / self.filename\n",
    "        \n",
    "        if target_path.exists():\n",
    "            print(\"File already downloaded\")\n",
    "            return target_path\n",
    "            \n",
    "        print(f\"Downloading from {url}\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(target_path, 'wb') as file:\n",
    "            for data in tqdm(response.iter_content(1024), total=total_size//1024, unit='KB', desc=self.filename):\n",
    "                file.write(data)\n",
    "                \n",
    "        print(\"Download completed\")\n",
    "        return target_path\n",
    "\n",
    "    def extract_files(self, archive_path):\n",
    "        \"\"\"Extract downloaded tar.bz2 file\"\"\"\n",
    "        print(f\"Extracting {archive_path}\")\n",
    "        with tarfile.open(archive_path, 'r:bz2') as tar:\n",
    "            tar.extractall(path=self.output_dir)\n",
    "        print(\"Extraction completed\")\n",
    "\n",
    "    def process_fasta(self):\n",
    "        \"\"\"Process extracted FASTA files\"\"\"\n",
    "        fasta_files = list(self.output_dir.glob('**/*.fasta'))\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        \n",
    "        for fasta in fasta_files:\n",
    "            if 'resistant' in fasta.stem.lower():\n",
    "                label = 1  # Resistant\n",
    "            else:\n",
    "                label = 0  # Sensitive\n",
    "                \n",
    "            with open(fasta) as f:\n",
    "                current_seq = ''\n",
    "                for line in f:\n",
    "                    if line.startswith('>'):\n",
    "                        if current_seq:\n",
    "                            sequences.append(current_seq)\n",
    "                            labels.append(label)\n",
    "                        current_seq = ''\n",
    "                    else:\n",
    "                        current_seq += line.strip()\n",
    "                if current_seq:\n",
    "                    sequences.append(current_seq)\n",
    "                    labels.append(label)\n",
    "        return sequences, labels\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Execute complete download and processing pipeline\"\"\"\n",
    "        archive_path = self.download_file()\n",
    "        self.extract_files(archive_path)\n",
    "        return self.process_fasta()\n",
    "\n",
    "# Download and process data\n",
    "downloader = DataDownloader()\n",
    "sequences, labels = downloader.run()\n",
    "print(f\"Loaded {len(sequences)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train model\n",
    "model = AMRModel()\n",
    "\n",
    "# Train with progress tracking\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "progress = widgets.FloatProgress(value=0, min=0, max=100, description='Training:')\n",
    "display(progress)\n",
    "\n",
    "def update_progress(epoch, logs):\n",
    "    progress.value = (epoch + 1) * 100 / epochs\n",
    "\n",
    "epochs = 10\n",
    "history = model.train(sequences, labels, epochs=epochs)\n",
    "progress.value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process data\n",
    "downloader = DataDownloader()\n",
    "sequences, labels = downloader.run()\n",
    "print(f\"Loaded {len(sequences)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train model\n",
    "model = AMRModel()\n",
    "\n",
    "# Train with progress tracking\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "progress = widgets.FloatProgress(value=0, min=0, max=100, description='Training:')\n",
    "display(progress)\n",
    "\n",
    "def update_progress(epoch, logs):\n",
    "    progress.value = (epoch + 1) * 100 / epochs\n",
    "\n",
    "epochs = 10\n",
    "history = model.train(sequences, labels, epochs=epochs)\n",
    "progress.value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(history['loss'], label='Training Loss')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction interface\n",
    "def predict_sequence(sequence):\n",
    "    try:\n",
    "        result = model.predict_sequence(sequence)\n",
    "        return HTML(f\"\"\"\n",
    "        <div style='background:#f0f0f0;padding:10px;border-radius:5px'>\n",
    "            <h3>Analysis Results:</h3>\n",
    "            <p><b>Sequence:</b> {sequence[:50]}...</p>\n",
    "            <p><b>Prediction:</b> {'Resistant' if result['class'] == 1 else 'Sensitive'}</p>\n",
    "            <p><b>Confidence:</b> {result['confidence']:.2f}%</p>\n",
    "        </div>\"\"\")\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create interactive widgets\n",
    "sequence_input = widgets.Textarea(\n",
    "    value='ATGCATGCATGC',\n",
    "    description='DNA Sequence:',\n",
    "    layout={'width': '100%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(description='Predict')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        display(predict_sequence(sequence_input.value))\n",
    "\n",
    "predict_button.on_click(on_button_click)\n",
    "\n",
    "display(sequence_input, predict_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "\n",
    "Upload a FASTA file for batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "def process_uploaded_fasta():\n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        results = []\n",
    "        \n",
    "        for filename, content in uploaded.items():\n",
    "            print(f\"Processing {filename}...\")\n",
    "            sequences = []\n",
    "            headers = []\n",
    "            current_header = ''\n",
    "            current_seq = ''\n",
    "            \n",
    "            for line in io.StringIO(content.decode('utf-8')):\n",
    "                line = line.strip()\n",
    "                if line.startswith('>'):\n",
    "                    if current_seq:\n",
    "                        sequences.append(current_seq)\n",
    "                        headers.append(current_header)\n",
    "                    current_header = line[1:]\n",
    "                    current_seq = ''\n",
    "                else:\n",
    "                    current_seq += line\n",
    "                    \n",
    "            if current_seq:\n",
    "                sequences.append(current_seq)\n",
    "                headers.append(current_header)\n",
    "                \n",
    "            # Process sequences with progress bar\n",
    "            for header, seq in tqdm(zip(headers, sequences), total=len(sequences), desc=\"Predicting\"):\n",
    "                try:\n",
    "                    result = model.predict_sequence(seq)\n",
    "                    results.append({\n",
    "                        'header': header,\n",
    "                        'sequence': seq[:50] + '...',\n",
    "                        'prediction': 'Resistant' if result['class'] == 1 else 'Sensitive',\n",
    "                        'confidence': f\"{result['confidence']:.2f}%\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    results.append({\n",
    "                        'header': header,\n",
    "                        'sequence': seq[:50] + '...',\n",
    "                        'prediction': 'Error',\n",
    "                        'confidence': str(e)\n",
    "                    })\n",
    "        \n",
    "        # Create and display results DataFrame\n",
    "        if results:\n",
    "            df = pd.DataFrame(results)\n",
    "            display(HTML(\"<h3>Prediction Results:</h3>\"))\n",
    "            display(HTML(df.to_html(index=False)))\n",
    "            \n",
    "            # Save results to CSV\n",
    "            output_file = 'prediction_results.csv'\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"\\nResults saved to {output_file}\")\n",
    "        else:\n",
    "            print(\"No sequences processed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {str(e)}\")\n",
    "\n",
    "print(\"Upload a FASTA file for batch prediction:\")\n",
    "process_uploaded_fasta()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
